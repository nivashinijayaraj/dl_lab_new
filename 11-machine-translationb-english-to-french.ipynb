{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9616616,"sourceType":"datasetVersion","datasetId":5868794}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport tensorflow_datasets as tfds\n\n# Step 1: Load dataset from CSV using Pandas\ndata_path = '/kaggle/input/wmt-sampled-50000-english-to-french-dataset/wmt_sample_50000.csv'\ndata = pd.read_csv(data_path)\n\n# Check the first few rows and the column names of the dataframe\nprint(data.head())\nprint(\"Columns in the DataFrame:\", data.columns.tolist())  # Print the actual column names\n\n# Ensure the dataframe contains the required columns\nexpected_columns = ['en', 'fr']\nassert all(col in data.columns for col in expected_columns), f\"CSV must contain {expected_columns} columns\"\n\n# Step 1.1: Preprocess the data\n# Drop rows with missing or non-string values\ndata = data.dropna(subset=['en', 'fr'])  # Drop rows where 'en' or 'fr' is NaN\ndata['en'] = data['en'].astype(str)  # Ensure 'en' column is of type string\ndata['fr'] = data['fr'].astype(str)  # Ensure 'fr' column is of type string\n\n# Step 2: Convert the DataFrame to a TensorFlow Dataset\ntrain_dataset = tf.data.Dataset.from_tensor_slices((data['en'].values, data['fr'].values))\n\n# Print the first example to verify conversion\nfor english, french in train_dataset.take(1):\n    print(f'English: {english.numpy().decode(\"utf-8\")}, French: {french.numpy().decode(\"utf-8\")}')\n\n# Optional: Define constants for batch size and max length\nBATCH_SIZE = 64\nMAX_LENGTH = 40\n\n# Optional: Tokenization process\ntokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n    (en.numpy() for en, fr in train_dataset), target_vocab_size=2**13)\ntokenizer_fr = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n    (fr.numpy() for en, fr in train_dataset), target_vocab_size=2**13)\n\n# Encoding function\ndef encode(en_t, fr_t):\n    en_t = [tokenizer_en.vocab_size] + tokenizer_en.encode(en_t.numpy().decode('utf-8')) + [tokenizer_en.vocab_size + 1]\n    fr_t = [tokenizer_fr.vocab_size] + tokenizer_fr.encode(fr_t.numpy().decode('utf-8')) + [tokenizer_fr.vocab_size + 1]\n    return en_t, fr_t\n\ndef tf_encode(en_t, fr_t):\n    return tf.py_function(encode, [en_t, fr_t], [tf.int64, tf.int64])\n\n# Prepare the dataset with encoding\ntrain_dataset = train_dataset.map(tf_encode)\n\n# Filter sequences longer than MAX_LENGTH\ndef filter_max_length(en, fr, max_length=MAX_LENGTH):\n    return tf.logical_and(tf.size(en) <= max_length, tf.size(fr) <= max_length)\n\ntrain_dataset = train_dataset.filter(lambda en, fr: filter_max_length(en, fr, MAX_LENGTH))\n\n# Shuffle and batch the dataset\ntrain_dataset = train_dataset.shuffle(20000).padded_batch(BATCH_SIZE, padded_shapes=([None], [None]))\ntrain_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n\n# Print the first training example after processing\nfor en, fr in train_dataset.take(1):\n    print(f'Encoded English: {en.numpy()}')\n    print(f'Encoded French: {fr.numpy()}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T10:26:24.852379Z","iopub.execute_input":"2024-10-18T10:26:24.853454Z","iopub.status.idle":"2024-10-18T10:32:38.726822Z","shell.execute_reply.started":"2024-10-18T10:26:24.853390Z","shell.execute_reply":"2024-10-18T10:32:38.725719Z"}},"outputs":[{"name":"stdout","text":"   Unnamed: 0                                                 en  \\\n0           0  Survey participants noted that growth in the s...   \n1           1  Influenza B was reported in a very small propo...   \n2           2  If you are travelling with infants or small ch...   \n3           3     ◦ Failure to provide a social insurance number   \n4           4  This often includes arrangements of traps and ...   \n\n                                                  fr  \n0  Les participants à l’enquête notent que la cro...  \n1  Le virus de l'influenza B a été signalé dans u...  \n2  Emportez également un double de votre ordonnan...  \n3  ◦ Défaut de fournir un numéro d'assurance sociale  \n4  Le circuit comprend souvent des systèmes de pi...  \nColumns in the DataFrame: ['Unnamed: 0', 'en', 'fr']\nEnglish: Survey participants noted that growth in the second quarter will likely be substantial, particularly in the corporate travel segment, compared with the dismal performance of the second quarter of 2003, when the impact of the war in Iraq and SARS outbreak sent bookings into a nose dive., French: Les participants à l’enquête notent que la croissance sera probablement importante au deuxième trimestre, en particulier dans le segment des voyages d’affaires, comparativement au rendement lamentable du deuxième trimestre de 2003, alors que la guerre en Iraq et de l’épidémie de SRAS ont fait plonger les réservations.\nEncoded English: [[8223 1697 2970 ...    0    0    0]\n [8223 7571 2519 ...    0    0    0]\n [8223 1961  361 ...    0    0    0]\n ...\n [8223 4968   89 ...    0    0    0]\n [8223   14 4598 ...    0    0    0]\n [8223 5321   26 ...    0    0    0]]\nEncoded French: [[8249 1853 3616 ...    0    0    0]\n [8249   49 5578 ...    0    0    0]\n [8249 2523  397 ...    0    0    0]\n ...\n [8249 7952 8025 ...    0    0    0]\n [8249   33 2681 ...    0    0    0]\n [8249 7198 5916 ...    0    0    0]]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}