{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4607952,"sourceType":"datasetVersion","datasetId":2604803},{"sourceId":9107706,"sourceType":"datasetVersion","datasetId":5496691}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**A] Basic object classification using pre-trained VGG16 Model**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nfrom keras.applications.vgg16 import VGG16, preprocess_input\n\nfrom keras.models import Model\n\nfrom keras.layers import Dense, Flatten\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.optimizers import Adam\n\nfrom keras.callbacks import EarlyStopping\n\nfrom keras.datasets import cifar10\n\nfrom keras.utils import to_categorical\n\n\n\n# Load the dataset\n\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\ny_train = to_categorical(y_train)\n\ny_test = to_categorical(y_test)\n\n\n\n# Load the VGG16 model without the top fully connected layers\n\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\n\n\n# Add custom layers on top of the base model\n\nx = Flatten()(base_model.output)\n\nx = Dense(256, activation='relu')(x)\n\npredictions = Dense(10, activation='softmax')(x)\n\n\n\n# Define the complete model\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n\n\n# Freeze the base model layers\n\nfor layer in base_model.layers:\n\n    layer.trainable = False\n\n\n\n# Compile the model\n\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\n\n\n# Preprocess the data\n\nx_train = preprocess_input(x_train)\n\nx_test = preprocess_input(x_test)\n\n\n\n# Create data generators for data augmentation\n\ndatagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n\ndatagen.fit(x_train)\n\n\n\n# Train the model\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nmodel.fit(datagen.flow(x_train, y_train, batch_size=32), validation_data=(x_test, y_test), epochs=5, callbacks=[early_stopping])\n\n\n\n# Evaluate the model on test data\n\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\n\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n","metadata":{"execution":{"iopub.execute_input":"2024-08-16T05:07:32.348833Z","iopub.status.busy":"2024-08-16T05:07:32.347820Z","iopub.status.idle":"2024-08-16T05:39:10.310519Z","shell.execute_reply":"2024-08-16T05:39:10.309303Z","shell.execute_reply.started":"2024-08-16T05:07:32.348786Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 238ms/step - accuracy: 0.4716 - loss: 3.2430 - val_accuracy: 0.6016 - val_loss: 1.1720\n","Epoch 2/5\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 236ms/step - accuracy: 0.6010 - loss: 1.1403 - val_accuracy: 0.6388 - val_loss: 1.0698\n","Epoch 3/5\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 237ms/step - accuracy: 0.6259 - loss: 1.0717 - val_accuracy: 0.6423 - val_loss: 1.0525\n","Epoch 4/5\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 231ms/step - accuracy: 0.6407 - loss: 1.0310 - val_accuracy: 0.6449 - val_loss: 1.0692\n","Epoch 5/5\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 232ms/step - accuracy: 0.6522 - loss: 0.9957 - val_accuracy: 0.6435 - val_loss: 1.0839\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 185ms/step - accuracy: 0.6393 - loss: 1.0701\n","Test Accuracy: 64.23%\n"]}],"execution_count":3},{"cell_type":"markdown","source":"**b] ImageNet Classification with Deep residual Networks (RESNET)**","metadata":{}},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n\nfrom keras.preprocessing import image\n\nimport numpy as np\n\n\n\n# Load the pre-trained ResNet50 model\n\nmodel = ResNet50(weights='imagenet')\n\n\n\n# Load an image file that contains an image to be classified\n\nimg_path = '/kaggle/input/rought-girl-dog-image/dogand girl image.jpg'  # Replace with the path to your image\n\nimg = image.load_img(img_path, target_size=(224, 224))\n\n\n\n# Convert the image to a numpy array\n\nx = image.img_to_array(img)\n\n\n\n# Add a batch dimension (since the model expects a batch of images)\n\nx = np.expand_dims(x, axis=0)\n\n\n\n# Preprocess the input image for the model\n\nx = preprocess_input(x)\n\n\n\n# Predict the class of the image\n\npredictions = model.predict(x)\n\n\n\n# Decode the top 3 predictions into human-readable class names\n\nprint('Predicted:', decode_predictions(predictions, top=3)[0])\n","metadata":{"execution":{"iopub.execute_input":"2024-08-16T05:45:54.723494Z","iopub.status.busy":"2024-08-16T05:45:54.722328Z","iopub.status.idle":"2024-08-16T05:45:58.917519Z","shell.execute_reply":"2024-08-16T05:45:58.915560Z","shell.execute_reply.started":"2024-08-16T05:45:54.723407Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n","\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Predicted: [('n02099849', 'Chesapeake_Bay_retriever', 0.1605571), ('n02109047', 'Great_Dane', 0.1506795), ('n02099267', 'flat-coated_retriever', 0.10858369)]\n"]}],"execution_count":5},{"cell_type":"code","source":"# both are same ","metadata":{"execution":{"iopub.execute_input":"2024-09-25T15:27:03.321482Z","iopub.status.busy":"2024-09-25T15:27:03.320000Z","iopub.status.idle":"2024-09-25T15:27:03.348500Z","shell.execute_reply":"2024-09-25T15:27:03.347172Z","shell.execute_reply.started":"2024-09-25T15:27:03.321404Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n\nfrom keras.preprocessing import image\n\nimport numpy as np\n\n\n\n# Load the pre-trained ResNet50 model\n\nmodel = ResNet50(weights='imagenet')\n\n\n\n# Load an image file that contains an image to be classified\n\nimg_path = '/kaggle/input/rought-girl-dog-image/dogand girl image.jpg'  # Replace with your image path\n\nimg = image.load_img(img_path, target_size=(224, 224))\n\n\n\n# Convert the image to a numpy array\n\nx = image.img_to_array(img)\n\n\n\n# Add a batch dimension\n\nx = np.expand_dims(x, axis=0)\n\n\n\n# Preprocess the input image\n\nx = preprocess_input(x)\n\n\n\n# Predict the class of the image\n\npredictions = model.predict(x)\n\n\n\n# Decode and print the top 3 predicted classes with their probabilities\n\nprint('Predicted:', decode_predictions(predictions, top=3)[0])\n","metadata":{"execution":{"iopub.execute_input":"2024-08-23T03:34:52.552558Z","iopub.status.busy":"2024-08-23T03:34:52.552042Z","iopub.status.idle":"2024-08-23T03:35:15.092167Z","shell.execute_reply":"2024-08-23T03:35:15.090952Z","shell.execute_reply.started":"2024-08-23T03:34:52.552521Z"}},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-23 03:34:55.173554: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-23 03:34:55.173777: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-23 03:34:55.359643: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n","\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n","\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Predicted: [('n02099849', 'Chesapeake_Bay_retriever', 0.1605571), ('n02109047', 'Great_Dane', 0.1506795), ('n02099267', 'flat-coated_retriever', 0.10858369)]\n"]}],"execution_count":1},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"C] Classifying species of Flowers using Transfer Learning","metadata":{}},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\n\nfrom keras.models import Model\n\nfrom keras.layers import Dense, Flatten\n\nfrom keras.optimizers import Adam\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.callbacks import EarlyStopping\n\n\n\n# Set up data directories\n\ntrain_dir = '/kaggle/input/flower-classification-5-classes-roselilyetc/Flower Classification/Flower Classification/Training Data'\n\nvalid_dir = '/kaggle/input/flower-classification-5-classes-roselilyetc/Flower Classification/Flower Classification/Testing Data'\n\n\n\n# Create data generators\n\ntrain_datagen = ImageDataGenerator(rescale=1./255)\n\nvalid_datagen = ImageDataGenerator(rescale=1./255)\n\n\n\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size=(224, 224),\n\n                                                    batch_size=32, class_mode='categorical')\n\nvalid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(224, 224),\n\n                                                    batch_size=32, class_mode='categorical')\n\n\n\n# Load the pre-trained VGG16 model without the top fully connected layers\n\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n\n\n# Add custom layers on top of the base model\n\nx = base_model.output\n\nx = Flatten()(x)\n\nx = Dense(256, activation='relu')(x)\n\npredictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n\n\n\n# Define the complete model\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n\n\n# Freeze the base model layers\n\nfor layer in base_model.layers:\n\n    layer.trainable = False\n\n\n\n# Compile the model\n\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\n\n\n# Set up early stopping\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n\n\n# Train the model\n\nmodel.fit(train_generator, epochs=5, validation_data=valid_generator, callbacks=[early_stopping])\n\n\n\n# Evaluate the model on validation data\n\nloss, accuracy = model.evaluate(valid_generator)\n\nprint(f'Validation Accuracy: {accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.execute_input":"2024-08-23T03:43:42.426654Z","iopub.status.busy":"2024-08-23T03:43:42.426203Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 5000 images belonging to 5 classes.\n","Found 958 images belonging to 5 classes.\n","Epoch 1/5\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1714s\u001b[0m 11s/step - accuracy: 0.6493 - loss: 1.3760 - val_accuracy: 0.8006 - val_loss: 0.6285\n","Epoch 2/5\n","\u001b[1m 19/157\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:57\u001b[0m 9s/step - accuracy: 0.9222 - loss: 0.2260"]}],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}