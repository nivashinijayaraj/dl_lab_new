{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1628138,"sourceType":"datasetVersion","datasetId":950271},{"sourceId":7132273,"sourceType":"datasetVersion","datasetId":4115102}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"A) Basic Entailment Using simple Rule Based Method ","metadata":{}},{"cell_type":"code","source":"# Step 1: Import Required Libraries\n\nimport pandas as pd\n\nimport nltk\n\nfrom sklearn.metrics import accuracy_score\n\n\n\n# Download necessary resources for NLTK\n\nnltk.download('punkt')\n\n\n\n# Step 2: Load the Dataset\n\n# Assume the dataset is in the form of a CSV file containing two sentences and a label ('entailment' or 'non-entailment')\n\n# Replace 'text_entailment_dataset.csv' with the path to your dataset\n\ndata = pd.read_csv('/kaggle/input/textual-entailment-dataset/validation.csv')\n\n\n\n# Step 3: Preprocess the Data\n\n# Function to preprocess text by tokenizing and converting to lowercase\n\ndef preprocess(text):\n\n    return nltk.word_tokenize(text.lower())\n\n\n\n# Apply preprocessing to both sentences in each pair\n\ndata['sentence1_tokens'] = data['text1'].apply(preprocess)\n\ndata['sentence2_tokens'] = data['text2'].apply(preprocess)\n\n\n\n# Step 4: Define Simple Rule-Based Method\n\n# Function to check if all tokens in sentence2 are in sentence1\n\ndef simple_rule_based_entailment(s1, s2):\n\n    return set(s2).issubset(set(s1))\n\n\n\n# Apply the rule-based method to each sentence pair\n\ndata['prediction'] = data.apply(lambda row: simple_rule_based_entailment(row['sentence1_tokens'], row['sentence2_tokens']), axis=1)\n\n\n\n# Step 5: Evaluate the Model\n\n# Calculate the accuracy of the predictions\n\naccuracy = accuracy_score(data['label'], data['prediction'])\n\nprint(f'Accuracy: {accuracy}')\n\n\n\n\n\n# Sample Input:\n\nsentence1 = \"The cat is on the mat.\"\n\nsentence2 = \"The mat has a cat.\"\n\n\n\n# Preprocess the sample input\n\nsentence1_tokens = preprocess(sentence1)\n\nsentence2_tokens = preprocess(sentence2)\n\n\n\n# Check if entailment is predicted\n\nis_entailment = simple_rule_based_entailment(sentence1_tokens, sentence2_tokens)\n\nprint(f'Entailment: {is_entailment}')\n","metadata":{"execution":{"iopub.execute_input":"2024-10-05T15:54:17.662685Z","iopub.status.busy":"2024-10-05T15:54:17.662281Z","iopub.status.idle":"2024-10-05T15:54:20.770420Z","shell.execute_reply":"2024-10-05T15:54:20.769229Z","shell.execute_reply.started":"2024-10-05T15:54:17.662647Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","Accuracy: 0.33876719307182884\n","Entailment: False\n"]}],"execution_count":3},{"cell_type":"markdown","source":"B. Natural Language Inference with Bert","metadata":{}},{"cell_type":"code","source":"# Step 1: Import Required Libraries\n\nfrom datasets import load_dataset\n\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n\nimport torch\n\n\n\n# Step 2: Load the Dataset\n\ndataset = load_dataset('snli')\n\n\n\n# Check the first few examples to understand the structure\n\nprint(dataset['train'].features)  # Check the features of the training dataset\n\nprint(dataset['train'][0:5])       # Print the first 5 examples from the training dataset\n\n\n\n# Step 3: Preprocess the Data\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n\n\ndef preprocess_function(examples):\n\n    return tokenizer(examples['premise'], examples['hypothesis'], truncation=True, padding='max_length', max_length=128)\n\n\n\n# Apply preprocessing to the dataset (train, validation, and test splits)\n\nencoded_dataset = dataset.map(preprocess_function, batched=True)\n\n\n\n# Check the structure of the dataset again\n\nprint(encoded_dataset)\n\n\n\n# Step 4: Inspect the label column directly to understand its structure\n\nprint(\"Label examples:\")\n\nprint(encoded_dataset['train']['label'][0:5])  # Print the first 5 labels\n\n\n\n# Step 5: Identify unique labels\n\nunique_labels = set(encoded_dataset['train']['label'])\n\nprint(f\"Unique labels in the dataset: {unique_labels}\")\n\n\n\n# Step 6: Define label mapping and handle unexpected labels\n\nlabel_dict = {0: 0, 1: 1, 2: 2}  # Adjust this as necessary based on your labels\n\n\n\n# Step 7: Map the labels correctly, handle unexpected labels\n\ndef map_labels(example):\n\n    # Use the label_dict for mapping, and set a default for unexpected labels\n\n    label = example['label']\n\n    return {'labels': label_dict.get(label, -1)}  # Map to -1 if the label is unexpected\n\n\n\nencoded_dataset = encoded_dataset.map(map_labels)\n\n\n\n# Set the format for PyTorch\n\nencoded_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n\n\n\n# Step 8: Load the Pre-Trained BERT Model\n\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n\n\n\n# Step 9: Set Up Training Arguments and Trainer\n\ntraining_args = TrainingArguments(\n\n    output_dir='./results',          # Output directory\n\n    evaluation_strategy='epoch',     # Evaluation during each epoch\n\n    per_device_train_batch_size=16,  # Batch size for training\n\n    per_device_eval_batch_size=16,   # Batch size for evaluation\n\n    num_train_epochs=3,              # Number of training epochs\n\n    weight_decay=0.01,               # Strength of L2 regularization\n\n    logging_dir='./logs',            # Directory for logs\n\n)\n\n\n\n# Initialize the Trainer with the model, training arguments, and datasets\n\ntrainer = Trainer(\n\n    model=model,                         # The BERT model for training\n\n    args=training_args,                  # Training arguments\n\n    train_dataset=encoded_dataset['train'],  # Training dataset\n\n    eval_dataset=encoded_dataset['validation'],  # Validation dataset\n\n)\n\n\n\n# Step 10: Train the Model\n\ntrainer.train()\n\n\n\n# Step 11: Evaluate the Model\n\neval_results = trainer.evaluate()\n\nprint(f\"Evaluation Results: {eval_results}\")\n\n\n\n# Step 12: Make Predictions\n\npremise = \"A man inspects the uniform of a figure in some East Asian country.\"\n\nhypothesis = \"The man is sleeping.\"\n\n\n\n# Tokenize the input example\n\ninputs = tokenizer(premise, hypothesis, return_tensors='pt', padding=True, truncation=True, max_length=128)\n\n\n\n# Get model prediction\n\nmodel.eval()\n\nwith torch.no_grad():\n\n    outputs = model(**inputs)\n\n    predicted_label = torch.argmax(outputs.logits).item()\n\n\n\n# Convert prediction to human-readable label\n\nlabel_map = {0: 'entailment', 1: 'contradiction', 2: 'neutral'}\n\nprint(f\"Predicted Label: {label_map[predicted_label]}\")\n","metadata":{"execution":{"iopub.execute_input":"2024-10-05T17:04:04.257513Z","iopub.status.busy":"2024-10-05T17:04:04.256983Z"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{'premise': Value(dtype='string', id=None), 'hypothesis': Value(dtype='string', id=None), 'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)}\n","{'premise': ['A person on a horse jumps over a broken down airplane.', 'A person on a horse jumps over a broken down airplane.', 'A person on a horse jumps over a broken down airplane.', 'Children smiling and waving at camera', 'Children smiling and waving at camera'], 'hypothesis': ['A person is training his horse for a competition.', 'A person is at a diner, ordering an omelette.', 'A person is outdoors, on a horse.', 'They are smiling at their parents', 'There are children present'], 'label': [1, 2, 0, 1, 0]}\n","DatasetDict({\n","    test: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 10000\n","    })\n","    validation: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 10000\n","    })\n","    train: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 550152\n","    })\n","})\n","Label examples:\n","[1, 2, 0, 1, 0]\n","Unique labels in the dataset: {0, 1, 2, -1}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b17b2e4d71d4dec9041a1380580dce5","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"857a678713f44504a2db27d0ffe3ca09","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"169a20d829eb4574972904c1fa41de04","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/550152 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51b6d7732c0d425980747141b09ca799","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]}],"execution_count":null},{"cell_type":"code","source":"C) Sentence Pair Classification Using Siamese Networks","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Required imports\n\nfrom sentence_transformers import SentenceTransformer\n\nfrom tensorflow.keras import layers, models, optimizers\n\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\n\nimport numpy as np\n\n\n\n# 1. Preprocess the Data: Load dataset and generate embeddings\n\ndata = pd.read_csv('sentence_similarity_dataset.csv')\n\n\n\n# Load a pre-trained Sentence Transformer model for generating sentence embeddings\n\nmodel = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n\n\n\n# Get sentence embeddings\n\ndata['sentence1_embedding'] = data['sentence1'].apply(lambda x: model.encode(x))\n\ndata['sentence2_embedding'] = data['sentence2'].apply(lambda x: model.encode(x))\n\n\n\n# Convert embeddings to numpy array\n\nX1 = np.array(data['sentence1_embedding'].tolist())\n\nX2 = np.array(data['sentence2_embedding'].tolist())\n\ny = data['similarity_label'].values  # Assuming the dataset has a column for similarity labels\n\n\n\n# Split the data into training and test sets\n\nX1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(X1, X2, y, test_size=0.2, random_state=42)\n\n\n\n# 2. Define the Siamese Network Architecture\n\n# Input layers for the two sentences\n\ninput1 = layers.Input(shape=(X1.shape[1],))\n\ninput2 = layers.Input(shape=(X1.shape[1],))\n\n\n\n# Dense layers for feature extraction\n\ndense_layer = layers.Dense(128, activation='relu')\n\nencoded1 = dense_layer(input1)\n\nencoded2 = dense_layer(input2)\n\n\n\n# Concatenate the extracted features and add a final dense layer for output\n\nmerged = layers.concatenate([encoded1, encoded2])\n\noutput = layers.Dense(1, activation='sigmoid')(merged)\n\n\n\n# Define the Siamese model\n\nsiamese_model = models.Model(inputs=[input1, input2], outputs=output)\n\n\n\n# Compile the model\n\nsiamese_model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\n\n\n# 3. Train the model\n\nsiamese_model.fit([X1_train, X2_train], y_train, epochs=5, batch_size=32, validation_split=0.2)\n\n\n\n# 4. Evaluate the Model\n\n# Predict on the test set\n\ny_pred = siamese_model.predict([X1_test, X2_test])\n\n\n\n# Convert predictions to binary (similar or not similar)\n\ny_pred = (y_pred > 0.5).astype(int)\n\n\n\n# Calculate accuracy\n\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f'Test Accuracy: {accuracy:.4f}')\n","metadata":{},"outputs":[],"execution_count":null}]}